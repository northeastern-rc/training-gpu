{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "004c9ef9",
   "metadata": {},
   "source": [
    "```\n",
    "conda create -n tf-gpu tensorflow-gpu\n",
    "conda activate tf-gpu\n",
    "conda install anaconda\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fb34fb",
   "metadata": {},
   "source": [
    "TF doesn't allow easy switch between CPU and GPU. Requires notebook restart to switch, hence separate notebooks here for CPU and GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d42e1a6-c581-45bc-847d-7021eb980444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/bootcamp/gpu_training/tf_env/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b489ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a61bb6e",
   "metadata": {},
   "source": [
    "### GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f35821af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Device Number found: 0\n",
      "GPU found\n"
     ]
    }
   ],
   "source": [
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "print (f\"CUDA Device Number found: {os.environ['CUDA_VISIBLE_DEVICES']}\") \n",
    "if tf.test.gpu_device_name():\n",
    "    print('GPU found')\n",
    "else:\n",
    "    print(\"No GPU found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7325fcf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate TF is installed with CUDA support : True\n",
      "Validate GPU is available for compute: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print (f\"Validate TF is installed with CUDA support : {tf.test.is_built_with_cuda()}\")\n",
    "print (f\"Validate GPU is available for compute: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "242eb80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Version : 2.4.1\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "print (f\"TF Version : {tf.__version__}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf618919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 5000)\n"
     ]
    }
   ],
   "source": [
    "tensor1 = tf.random.normal([5000,10000])\n",
    "tensor2 = tf.random.normal([10000,5000])\n",
    "result = tf.matmul(tensor1, tensor2)\n",
    "print (result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "897e2055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.1 ms ± 11.6 ms per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 7 -n 1000\n",
    "tf.matmul(tensor1, tensor2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55d34fd4-ed81-446f-9876-54f2f46bfe5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jun  9 09:28:02 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 465.19.01    Driver Version: 465.19.01    CUDA Version: 11.3     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA Tesla P1...  Off  | 00000000:03:00.0 Off |                    0 |\n",
      "| N/A   66C    P0   220W / 250W |  11525MiB / 12198MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      6108      C   ...raining/tf_env/bin/python    11523MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645c9f88",
   "metadata": {},
   "source": [
    "GPU runtime ~ 36 ms with a high std. dev. of 5ms. Mean runtime is close to PyTorch GPU execution. \n",
    "\n",
    "> If you see warning, result may not be realistic to compare with PyTorch. But the code used GPU and ran much faster than TF's CPU only run. It is not straightforward to use cuda synchronize to prevent caching as we did in PyTorch. A possible way to use explicit sess.run(); https://discuss.pytorch.org/t/is-there-any-code-torch-backends-cudnn-benchmark-torch-cuda-synchronize-similar-in-tensorflow/51484"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
