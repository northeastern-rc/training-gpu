##Logging to Discovery:
ssh -Y <yourusername>@login.discovery.neu.edu

##Copying training material to Discovery using 'scp':
git clone git@github.com:northeastern-rc/training-gpu.git

##Exercise 1:
srun --partition=gpu --nodes=1 â€“-cpus-per-task=1 --pty --gres=gpu:p100:1 --mem=10G --time=02:00:00 /bin/bash

# Build tensorflow env from scratch in your $HOME directory:
module load anaconda3/2022.05
module load cuda/11.2
conda create --name TF_env python=3.9 -y #where TF_env is the name of the conda environment
source activate TF_env #load the virtual conda environment "TF_env"
export LD_LIBRARY_PATH=$HOME/.conda/envs/TF_env/lib:$LD_LIBRARY_PATH
conda install -c conda-forge cudatoolkit=11.2 cudnn=8.1.0 -y
pip install tensorflow


## Loading the pre-existing tf_env environment
module load cuda/11.1 
module load anaconda3/2021.05

# Load the environment we have already created for you:
source activate /work/bootcamp/gpu_training/tf_env

# Install gpu-enabled TF inside the virtual environment:
conda install -c anaconda tensorflow-gpu -y

# Test if GPU device is detected with TF:
python -c 'import tensorflow as tf; print(tf.test.is_built_with_cuda())'

# Deactivate conda environment
conda deactivate


## Exercise 2:
# Requesting a GPU node
srun --partition=gpu --nodes=1 --cpus-per-task=1 --gres=gpu:1 --mem=2G --time=00:05:00 --pty /bin/bash
nvidia-smi
exit

# Requesting a GPU node with a specific type of GPU
srun --partition=gpu --nodes=1 --cpus-per-task=1 --gres=gpu:p100:1 --mem=2G --time=00:05:00 --pty /bin/bash
nvidia-smi
exit

# Check available features on the GPU partition
sinfo -p gpu --Format=nodes,cpus,nodelist,gres,features
sinfo -p gpu --Format=nodes,cpus,nodelist,gres,statecompact,features


## Exercise 3
sbatch main_tf.bash

